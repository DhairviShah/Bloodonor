# -*- coding: utf-8 -*-
"""Dhairvi_Shah_1032230299_IVA_3_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_luds8pfJw96BWHBw0eAJtMz-AiZxqzY

Aim: To study and implement various video object segmentation techniques

Problem statement: To present a comparative study of various techniques for video object
segmentation for extracting the foreground.

Objectives:

● To learn various types of video segmentation techniques

● To implement various foreground extraction techniques

Methodology: Apply various video segmentation techniques for detecting/extracting object
from the given video

A. Image properties to be considered:

● Background subtraction (Frame difference method)

● The Mixture of Gaussian

B. Types of videos to be considered


● Uncluttered background

● Complex background


Discuss the algorithm used in each technique. Discuss the parameters on which type of
algorithm to be used depends.

**Background Subtraction (Frame Difference Method)**

For Uncluttered background
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow # Import cv2_imshow from google.colab.patches

# Load the video
cap = cv2.VideoCapture('/content/6882738915724233985.mp4')

# Initialize the first frame
ret, frame1 = cap.read()
prev_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)

# Start the foreground extraction
while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Convert the frame to grayscale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Calculate the difference between the current frame and the previous frame
    diff = cv2.absdiff(prev_gray, gray)

    # Threshold the difference image to separate the foreground from the background
    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)

    # Apply morphological operations to remove noise and fill gaps
    kernel = np.ones((3, 3), np.uint8)
    thresh = cv2.erode(thresh, kernel, iterations=2)
    thresh = cv2.dilate(thresh, kernel, iterations=2)

    # Extract the foreground object
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for contour in contours:
        (x, y, w, h) = cv2.boundingRect(contour)
        if cv2.contourArea(contour) > 1000:
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)

    # Display the output
    cv2_imshow(frame) # Use cv2_imshow instead of cv2.imshow

    # Update the previous frame
    prev_gray = gray

    # Exit on key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close the window
cap.release()
cv2.destroyAllWindows()

"""For Complex background"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow # Import cv2_imshow from google.colab.patches

# Load the video
cap = cv2.VideoCapture('/content/6875749962681044230.mp4')

# Initialize the first frame
ret, frame1 = cap.read()
prev_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)

# Start the foreground extraction
while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Convert the frame to grayscale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Calculate the difference between the current frame and the previous frame
    diff = cv2.absdiff(prev_gray, gray)

    # Threshold the difference image to separate the foreground from the background
    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)

    # Apply morphological operations to remove noise and fill gaps
    kernel = np.ones((3, 3), np.uint8)
    thresh = cv2.erode(thresh, kernel, iterations=2)
    thresh = cv2.dilate(thresh, kernel, iterations=2)

    # Extract the foreground object
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for contour in contours:
        (x, y, w, h) = cv2.boundingRect(contour)
        if cv2.contourArea(contour) > 1000:
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)

    # Display the output
    cv2_imshow(frame) # Use cv2_imshow instead of cv2.imshow

    # Update the previous frame
    prev_gray = gray

    # Exit on key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close the window
cap.release()
cv2.destroyAllWindows()

"""**The Mixture of Gaussian**

For Uncluttered Video
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow # Import cv2_imshow from google.colab.patches

# Load the video
cap = cv2.VideoCapture('/content/6882738915724233985.mp4')

# Initialize the background model
back_sub = cv2.createBackgroundSubtractorMOG2()

# Start the foreground extraction
while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Apply the background subtraction algorithm
    fg_mask = back_sub.apply(frame)

    # Apply morphological operations to remove noise and fill gaps
    kernel = np.ones((3, 3), np.uint8)
    fg_mask = cv2.erode(fg_mask, kernel, iterations=2)
    fg_mask = cv2.dilate(fg_mask, kernel, iterations=2)

    # Extract the foreground object
    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for contour in contours:
        (x, y, w, h) = cv2.boundingRect(contour)
        if cv2.contourArea(contour) > 1000:
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)

    # Display the output
    cv2_imshow(frame) # Pass only the frame to cv2_imshow

    # Exit on key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close the window
cap.release()
cv2.destroyAllWindows()

"""For Complex background"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow # Import cv2_imshow from google.colab.patches

# Load the video
cap = cv2.VideoCapture('/content/6875749962681044230.mp4')

# Initialize the background model
back_sub = cv2.createBackgroundSubtractorMOG2()

# Start the foreground extraction
while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Apply the background subtraction algorithm
    fg_mask = back_sub.apply(frame)

    # Apply morphological operations to remove noise and fill gaps
    kernel = np.ones((3, 3), np.uint8)
    fg_mask = cv2.erode(fg_mask, kernel, iterations=2)
    fg_mask = cv2.dilate(fg_mask, kernel, iterations=2)

    # Extract the foreground object
    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for contour in contours:
        (x, y, w, h) = cv2.boundingRect(contour)
        if cv2.contourArea(contour) > 1000:
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)

    # Display the output
    cv2_imshow(frame) # Pass only the frame to cv2_imshow

    # Exit on key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close the window
cap.release()
cv2.destroyAllWindows()

"""

**Background Subtraction (Frame Difference Method)**

Algorithm:

1. Capture a sequence of frames from the video.
2. Calculate the difference between the current frame and the previous frame using the frame difference method.
3. Threshold the difference image to separate the foreground from the background.
4. Apply morphological operations (e.g., erosion and dilation) to remove noise and fill gaps.
5. Extract the foreground object by selecting the pixels with high intensity values.

Parameters:

* Threshold value: determines the sensitivity of the algorithm to detect changes in the background.
* Morphological parameters (e.g., erosion and dilation size): affect the noise removal and gap filling.

Output:
The algorithm produces a binary image with the foreground object (high intensity values) and the background (low intensity values).

Observations:

* If the threshold value is too low, the algorithm may detect false positives (e.g., noise or shadows).
* If the threshold value is too high, the algorithm may miss some parts of the foreground object.
* Changing the morphological parameters can affect the quality of the foreground extraction.



**The Mixture of Gaussian**

Algorithm:

1. Model the background as a mixture of two Gaussian distributions: one for the background and one for the foreground.
2. Calculate the probability of each pixel belonging to the background or foreground using the Gaussian mixture model.
3. Threshold the probability values to separate the foreground from the background.
4. Apply morphological operations (e.g., erosion and dilation) to remove noise and fill gaps.
5. Extract the foreground object by selecting the pixels with high probability values.

Parameters:

* Number of Gaussian components: affects the accuracy of the background modeling.
* Threshold value: determines the sensitivity of the algorithm to detect changes in the background.
* Morphological parameters (e.g., erosion and dilation size): affect the noise removal and gap filling.

Output:
The algorithm produces a binary image with the foreground object (high probability values) and the background (low probability values).

Observations:

* If the number of Gaussian components is too low, the algorithm may not accurately model the background.
* If the threshold value is too low, the algorithm may detect false positives (e.g., noise or shadows).
* Changing the morphological parameters can affect the quality of the foreground extraction.

**Comparison and Conclusion**

Both algorithms are suitable for video object segmentation, but they have different strengths and weaknesses. The frame difference method is simple and fast but may be sensitive to noise and shadows. The Mixture of Gaussian is more robust and accurate but requires more computational resources and may be slower.

For uncluttered backgrounds, the frame difference method may produce good results, but for complex backgrounds, the Mixture of Gaussian may be more effective.

Comparison of the Two Algorithms:

**For Uncluttered Background Videos:**

For uncluttered background videos, both algorithms can produce good results. The frame difference method is simple and fast, and can detect the foreground object accurately. The Mixture of Gaussian algorithm can also work well, as it can model the background accurately and detect the foreground object.

However, if the background is very uniform and lacks texture, the frame difference method may be more effective, as it can detect even small changes in the background.

**For Complex Background Videos:**

For complex background videos, the Mixture of Gaussian algorithm is more suitable. The frame difference method can struggle with complex backgrounds, as it may detect false positives (e.g., noise or shadows) or miss some parts of the foreground object.

The Mixture of Gaussian algorithm can handle complex backgrounds more effectively, as it can model the background accurately and detect the foreground object even in the presence of noise or shadows.

In particular, the Mixture of Gaussian algorithm is more effective in the following scenarios:

- Backgrounds with multiple textures or
patterns

- Backgrounds with varying lighting conditions

- Backgrounds with moving objects or camera motion

In conclusion, the choice of algorithm depends on the specific video and the desired level of accuracy. For uncluttered backgrounds, the frame difference method may be a good starting point, but for complex backgrounds, the Mixture of Gaussian may be a better choice.


**Also from the output given above we can say that mixture of Gaussian method, though slow give better extracted region.**"""

